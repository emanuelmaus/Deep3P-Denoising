{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure: 3PM-Noise2Void"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter-notebook magic\n",
    "\n",
    "# For the matplotlib \n",
    "%matplotlib inline\n",
    "# For reload functions explicitly\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "## Add the modules to the system path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "\n",
    "## Libs\n",
    "from random import shuffle\n",
    "import glob\n",
    "import tifffile\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "cudnn.fastest = True\n",
    "\n",
    "## Own modules\n",
    "import utils\n",
    "from train import Trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select here, if mGFP or THG should be denoised #\n",
    "denoise_mGFP = True\n",
    "#************************************************#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the store path for the results and raw file here #\n",
    "path_results = os.path.join(\"..\", \"results_3PM-N2V\")\n",
    "if denoise_mGFP:\n",
    "    path_results = path_results+\"_mGFP\"\n",
    "else:\n",
    "    path_results = path_results+\"_THG\"\n",
    "\n",
    "path_dataset = os.path.join(\"..\", \"data\", \"3PM-N2V\")\n",
    "#********************************************************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the other paths based on the results folder\n",
    "\n",
    "# Make a folder to store results\n",
    "res_folder = os.path.join(path_results, 'training_results')\n",
    "os.makedirs(res_folder, exist_ok=True)\n",
    "\n",
    "# Make a folder to store the log files\n",
    "log_folder = os.path.join(path_results, 'log_files')\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "log_train_folder = os.path.join(log_folder, 'train')\n",
    "os.makedirs(log_train_folder, exist_ok=True)\n",
    "\n",
    "log_val_folder = os.path.join(log_folder, 'val')\n",
    "os.makedirs(log_val_folder, exist_ok=True)\n",
    "\n",
    "# Make a folder for the checkpoints\n",
    "checkpoint_folder = os.path.join(path_results, 'checkpoints')\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "# List all folders in the results folder to make sure all folder exists\n",
    "output_files = os.listdir(path_results)\n",
    "print(\"*****Output Folder*****\")\n",
    "print(\"List of all folder in the results path:\")\n",
    "print(output_files)\n",
    "print(\"***********************\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load image stack as dataset \n",
    "\n",
    "filenames_train = glob.glob(os.path.join(path_dataset, \"*-train.tif\"))\n",
    "filenames_val = glob.glob(os.path.join(path_dataset, \"*-validate.tif\"))\n",
    "print(\"On following file will be trained:  \", filenames_train[0])\n",
    "print(\"on following file will be validated:  \", filenames_val[0])\n",
    "\n",
    "file_train = tifffile.imread(filenames_train[0])\n",
    "file_val = tifffile.imread(filenames_val[0])\n",
    "\n",
    "if denoise_mGFP:\n",
    "    file_train = file_train[:,0].squeeze()\n",
    "    file_val = file_val[:,0].squeeze()\n",
    "else:\n",
    "    file_val = file_train[:,1].squeeze()\n",
    "    file_val = file_train[:,1].squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise2Void Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the blindspot parameters #\n",
    "percent_blindpixel = 20\n",
    "picking_radius = 5\n",
    "#*********************************#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training parameters #\n",
    "# Z x Y x X\n",
    "input_size = [16, 64, 64]\n",
    "\n",
    "# #Training-to-#Validation ratio\n",
    "train_val_fraction = 0.5\n",
    "\n",
    "# Training epochs\n",
    "epoch = 300\n",
    "\n",
    "# Batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Logger frequencies\n",
    "display_freq = 500\n",
    "model_storing_freq = 50\n",
    "#*********************************#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter dictionary\n",
    "parameter_dict= {}\n",
    "# paths\n",
    "# In case norm-factors are stored somewhere, not necessary\n",
    "parameter_dict['dir_norm_factors'] = os.path.join(\"no_norm_factors_stored\")\n",
    "parameter_dict['dir_checkpoint'] = checkpoint_folder\n",
    "parameter_dict['dir_log'] = log_folder\n",
    "parameter_dict['dir_result'] = res_folder\n",
    "# training state\n",
    "parameter_dict['train_continue'] = 'on'\n",
    "# hyperparameters\n",
    "parameter_dict['num_epoch'] = epoch\n",
    "# batch size\n",
    "parameter_dict['batch_size'] = batch_size\n",
    "# adam optimizer\n",
    "parameter_dict['lr'] = 0.001\n",
    "parameter_dict['optim'] = 'adam'\n",
    "parameter_dict['beta1'] = 0.5\n",
    "parameter_dict['beta2'] = 0.999\n",
    "# colormap\n",
    "parameter_dict['cmap'] = 'gray'\n",
    "# size of the input patches\n",
    "parameter_dict['ny'] = input_size[0]\n",
    "parameter_dict['nx'] = input_size[1]\n",
    "parameter_dict['nz'] = input_size[2]\n",
    "# channel dimension\n",
    "parameter_dict['nch'] = 1\n",
    "\n",
    "# augmentation data for the N2V augmenter\n",
    "parameter_dict['perc_pixel'] = percent_blindpixel\n",
    "parameter_dict['n2v_neighborhood_radius'] = picking_radius\n",
    "parameter_dict['structN2Vmask'] = None\n",
    "# logger parameter\n",
    "parameter_dict['num_freq_disp'] = display_freq\n",
    "parameter_dict['num_freq_save'] = model_storing_freq\n",
    "# datasets\n",
    "parameter_dict['train_dataset'] = [file_train]\n",
    "parameter_dict['val_dataset'] = [file_val[:-int(train_val_fraction*len(file_train))]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the parameters\n",
    "print(\"***** Parameters *****\")\n",
    "print(\"{\" + \"\\n\".join(\"{!r}: {!r},\".format(k, v) for k, v in parameter_dict.items()) + \"}\")\n",
    "print(\"**********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logger\n",
    "%tensorboard --logdir train:/../results_mGFP/log_files/train validation:/../results_mGFP/log_files/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Trainer\n",
    "trainer = Trainer(parameter_dict)\n",
    "# Start training\n",
    "print(\"*****Start of Training*****\")\n",
    "trainer.train()\n",
    "print(\"*****End of Training*******\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
