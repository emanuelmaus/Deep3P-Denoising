{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the matplotlib \n",
    "%matplotlib inline\n",
    "# For reload functions explicitly\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Add the modules to the system path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MaxBlurPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = torch.ones((8, 16, 16, 256,256))\n",
    "pool_kernel_size = (2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normal_pooling = torch.nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "test_sample_maxpool = normal_pooling(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 16, 256, 256])\n",
      "torch.Size([8, 16, 8, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(test_sample.size())\n",
    "print(test_sample_maxpool.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate MaxBlurPool3D for the N2V2 approach\n",
    "class MaxBlurPool3D(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, pool_kernel_size, blur_kernel=None):\n",
    "        super(MaxBlurPool3D, self).__init__()\n",
    "        self.pool_kernel_size = pool_kernel_size\n",
    "        self.blur_kernel = blur_kernel\n",
    "        self.kernel = None\n",
    "\n",
    "        if self.blur_kernel is None:\n",
    "            self.blur_kernel = torch.tensor(\n",
    "                [[[0.02595968, 0.03575371, 0.02595968],\n",
    "                [0.03575371, 0.04924282, 0.03575371],\n",
    "                [0.02595968, 0.03575371, 0.02595968]],\n",
    "\n",
    "                [[0.03575371, 0.04924282, 0.03575371],\n",
    "                [0.04924282, 0.06782107, 0.04924282],\n",
    "                [0.03575371, 0.04924282, 0.03575371]],\n",
    "\n",
    "                [[0.02595968, 0.03575371, 0.02595968],\n",
    "                [0.03575371, 0.04924282, 0.03575371],\n",
    "                [0.02595968, 0.03575371, 0.02595968]]],\n",
    "                dtype = torch.float32, \n",
    "                device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "            )\n",
    "            self.blur_kernel = self.blur_kernel / self.blur_kernel.sum()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.nn.functional.max_pool3d(x,\n",
    "                                           self.pool_kernel_size,\n",
    "                                           stride=1,\n",
    "                                           padding=self.pool_kernel_size[0]//2\n",
    "                                           )\n",
    "        if self.kernel is None:\n",
    "            self.kernel = self.blur_kernel[None].repeat_interleave(x.size(dim=1), dim=0)[None].repeat_interleave(x.size(dim=1), dim=0)\n",
    "        x = torch.nn.functional.conv3d(x,\n",
    "                                       weight=self.kernel,\n",
    "                                       stride=self.pool_kernel_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_maxpool = MaxBlurPool3D(pool_kernel_size)\n",
    "test_sample_blur = blur_maxpool(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 16, 256, 256])\n",
      "torch.Size([8, 16, 8, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(test_sample.size())\n",
    "print(test_sample_blur.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Noise2NoiseUNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submodules\n",
    "\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='cr', num_groups=8, padding=1):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
    "            self.add_module(name, module)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='cr', num_groups=8):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups))\n",
    "\n",
    "\n",
    "def conv3d(in_channels, out_channels, kernel_size, bias, padding=1):\n",
    "    return nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias)\n",
    "\n",
    "# Generate MaxBlurPool3D for the N2V2 approach\n",
    "class MaxBlurPool3d(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, pool_kernel_size, blur_kernel=None):\n",
    "        super(MaxBlurPool3d, self).__init__()\n",
    "        self.pool_kernel_size = pool_kernel_size\n",
    "        self.blur_kernel = blur_kernel\n",
    "        self.kernel = None\n",
    "\n",
    "        if self.blur_kernel is None:\n",
    "            self.blur_kernel = torch.tensor(\n",
    "                [[[0.02595968, 0.03575371, 0.02595968],\n",
    "                [0.03575371, 0.04924282, 0.03575371],\n",
    "                [0.02595968, 0.03575371, 0.02595968]],\n",
    "\n",
    "                [[0.03575371, 0.04924282, 0.03575371],\n",
    "                [0.04924282, 0.06782107, 0.04924282],\n",
    "                [0.03575371, 0.04924282, 0.03575371]],\n",
    "\n",
    "                [[0.02595968, 0.03575371, 0.02595968],\n",
    "                [0.03575371, 0.04924282, 0.03575371],\n",
    "                [0.02595968, 0.03575371, 0.02595968]]],\n",
    "                dtype = torch.float32, \n",
    "                device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "            )\n",
    "            self.blur_kernel = self.blur_kernel / self.blur_kernel.sum()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.nn.functional.max_pool3d(x,\n",
    "                                           self.pool_kernel_size,\n",
    "                                           stride=1,\n",
    "                                           padding=self.pool_kernel_size[0]//2\n",
    "                                           )\n",
    "        if self.kernel is None:\n",
    "            self.kernel = self.blur_kernel[None].repeat_interleave(x.size(dim=1), dim=0)[None].repeat_interleave(x.size(dim=1), dim=0)\n",
    "        x = torch.nn.functional.conv3d(x,\n",
    "                                       weight=self.kernel,\n",
    "                                       stride=self.pool_kernel_size)\n",
    "        return x\n",
    "       \n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=1):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int): add zero-padding to the input\n",
    "\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(negative_slope=0.1, inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of gatchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            modules.append(('conv', conv3d(in_channels, out_channels, kernel_size, bias, padding=padding)))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            assert not is_before_conv, 'GroupNorm MUST go after the Conv3d'\n",
    "            # number of groups must be less or equal the number of channels\n",
    "            if out_channels < num_groups:\n",
    "                num_groups = out_channels\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules\n",
    "\n",
    "## Encoder and Decoder Networks\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a DoubleConv module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (tuple): the size of the window to take a max over\n",
    "        pool_type (str): pooling layer: 'max' 'maxblur' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=(2, 2, 2), pool_type='max', basic_module=DoubleConv, conv_layer_order='cr',\n",
    "                 num_groups=8):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'maxblur', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            elif pool_type == 'maxblur':\n",
    "                self.pooling = MaxBlurPool3d(pool_kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsample layer\n",
    "    (either learned ConvTranspose3d or interpolation) followed by a DoubleConv\n",
    "    module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3,\n",
    "                 scale_factor=(2, 2, 2), basic_module=DoubleConv, conv_layer_order='cr', num_groups=8):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        if basic_module == DoubleConv:\n",
    "            # if DoubleConv is the basic_module use nearest neighbor interpolation for upsampling\n",
    "            self.upsample = None\n",
    "        else:\n",
    "            # otherwise use ConvTranspose3d (bear in mind your GPU memory)\n",
    "            # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "            # (D_out = (D_in − 1) ×  stride[0] − 2 ×  padding[0] +  kernel_size[0] +  output_padding[0])\n",
    "            # also scale the number of channels from in_channels to out_channels so that summation joining\n",
    "            # works correctly\n",
    "            self.upsample = nn.ConvTranspose3d(in_channels,\n",
    "                                               out_channels,\n",
    "                                               kernel_size=kernel_size,\n",
    "                                               stride=scale_factor,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1)\n",
    "            # adapt the number of in_channels for the ExtResNetBlock\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        if self.upsample is None:\n",
    "            # If it is the N2V2 Setup, we don't have encoder_features in the last layer of the U-net, encoder_features is then the output-shape\n",
    "            if type(encoder_features) is torch.Size:\n",
    "                output_size = encoder_features\n",
    "                print(\"Is a tuple\", encoder_features)\n",
    "                # use nearest neighbor interpolation\n",
    "                x = F.interpolate(x, size=output_size, mode='nearest')\n",
    "            else:\n",
    "                # use nearest neighbor interpolation and concatenation joining\n",
    "                output_size = encoder_features.size()[2:]\n",
    "                x = F.interpolate(x, size=output_size, mode='nearest')\n",
    "                # concatenate encoder_features (encoder path) with the upsampled input across channel dimension\n",
    "                x = torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            # use ConvTranspose3d and summation joining\n",
    "            x = self.upsample(x)\n",
    "            if not self.is_last_layer:\n",
    "                x += encoder_features\n",
    "\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "## Initialization function\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Parameters:\n",
    "        net (network)   -- network to be initialized\n",
    "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
    "\n",
    "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
    "    work better for some applications. Feel free to try yourself.\n",
    "    \"\"\"\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise2NoiseUNet3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual 3DUnet model implementation based on https://arxiv.org/pdf/1706.00120.pdf and https://www.nature.com/articles/s41592-021-01225-0.\n",
    "    Uses ExtResNetBlock instead of DoubleConv as a basic building block as well as summation joining instead\n",
    "    of concatenation joining. Since the model effectively becomes a residual net, in theory it allows for deeper UNet.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output segmentation masks;\n",
    "            Note that that the of out_channels might correspond to either\n",
    "            different semantic classes or to different binary segmentation mask.\n",
    "            It's up to the user of the class to interpret the out_channels and\n",
    "            use the proper loss criterion during training (i.e. NLLLoss (multi-class)\n",
    "            or BCELoss (two-class) respectively)\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4,5\n",
    "        init_channel_number (int): number of feature maps in the first conv layer of the encoder; default: 64\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        is_N2V2_setup (bool): Flag if using the N2V2 setup model (source: https://openreview.net/forum?id=IZfQYb4lHVq), which has no last skip connection and uses max-blurring \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, f_maps=16, num_groups=8, is_N2V2_setup=False, **kwargs):\n",
    "        super(Noise2NoiseUNet3D, self).__init__()\n",
    "\n",
    "        # Set flag if N2V2 or not\n",
    "        self.is_N2V2_setup = is_N2V2_setup\n",
    "        # Use LeakyReLU activation everywhere except the last layer\n",
    "        conv_layer_order = 'clg'\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            # use 5 levels in the encoder path as suggested in the paper\n",
    "            f_maps = self.__create_feature_maps(f_maps, number_of_fmaps=5)\n",
    "\n",
    "        # create encoder path consisting of Encoder modules. The length of the encoder is equal to `len(f_maps)`\n",
    "        # uses DoubleConv as a basic_module for the Encoder\n",
    "        encoders = []\n",
    "        for i, out_feature_num in enumerate(f_maps):\n",
    "            if i == 0:\n",
    "                encoder = Encoder(in_channels, out_feature_num, apply_pooling=False, basic_module=DoubleConv,\n",
    "                                  conv_layer_order=conv_layer_order, num_groups=num_groups)\n",
    "            else:\n",
    "                if self.is_N2V2_setup:\n",
    "                    encoder = Encoder(f_maps[i - 1], out_feature_num, basic_module=DoubleConv,\n",
    "                                    conv_layer_order=conv_layer_order, num_groups=num_groups, pool_type='maxblur')\n",
    "                else:\n",
    "                    encoder = Encoder(f_maps[i - 1], out_feature_num, basic_module=DoubleConv,\n",
    "                                    conv_layer_order=conv_layer_order, num_groups=num_groups)\n",
    "            encoders.append(encoder)\n",
    "\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # create decoder path consisting of the Decoder modules. The length of the decoder is equal to `len(f_maps) - 1`\n",
    "        # uses DoubleConv as a basic_module for the Decoder\n",
    "        decoders = []\n",
    "        reversed_f_maps = list(reversed(f_maps))\n",
    "        for i in range(len(reversed_f_maps) - 1):\n",
    "            if self.is_N2V2_setup and i==len(reversed_f_maps) - 2:\n",
    "                in_feature_num = reversed_f_maps[i]\n",
    "                print(\"Last layer\")\n",
    "                print(\"Reuglar output: \", reversed_f_maps[i] + reversed_f_maps[i + 1])\n",
    "            else:\n",
    "                in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "            out_feature_num = reversed_f_maps[i + 1]\n",
    "            decoder = Decoder(in_feature_num, out_feature_num, basic_module=DoubleConv,\n",
    "                              conv_layer_order=conv_layer_order, num_groups=num_groups)\n",
    "            print(\"Input channel: \", in_feature_num)\n",
    "            print(\"Output channel: \", out_feature_num)\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "        # 1x1x1 conv + simple ReLU in the final convolution\n",
    "        self.final_conv = SingleConv(f_maps[0], out_channels, kernel_size=1, order='cr', padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for ind, encoder in enumerate(self.encoders):\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            if self.is_N2V2_setup and ind==0:\n",
    "                encoders_features.insert(0, x.size()[2:])\n",
    "            else:\n",
    "                encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        running_var = 0\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            running_var = running_var + 1\n",
    "            print(\"Running variabl: \", running_var)\n",
    "            x = decoder(encoder_features, x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __create_feature_maps(self, init_channel_number, number_of_fmaps):\n",
    "        return [init_channel_number * 2 ** k for k in range(number_of_fmaps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Noise2NoiseUNet3D(1,1, is_N2V2_setup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = torch.rand((8,1,16,64,64))\n",
    "test_output = model(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 16, 64, 64])\n",
      "torch.Size([8, 1, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(test_batch.size())\n",
    "print(test_output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
